{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61687266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "def manhattan_distance(s, b):\n",
    "    return abs(s[0] - b[0]) + abs(s[1] - b[1])\n",
    "\n",
    "def find_four_points(s, md):\n",
    "    \"\"\"Input sensor and build all directions based on manhattan distance\"\"\"\n",
    "    \n",
    "    # col math\n",
    "    sc_neg = (s[0], s[1] - md)\n",
    "    sc_pos = (s[0], s[1] + md)\n",
    "    \n",
    "    # row math\n",
    "    sr_neg = (s[0] - md, s[1])\n",
    "    sr_pos = (s[0] + md, s[1])\n",
    "    \n",
    "    return (sc_neg, sc_pos, sr_neg, sr_pos)\n",
    "    \n",
    "def flattenArray(l):\n",
    "    return np.asarray([item for sublist in l for item in sublist])\n",
    "\n",
    "#ahh, we only need to build coverage for our row of interest.\n",
    "# can look for its position relative to higher & lower points\n",
    "def efficienct_coverage(sc_neg, sc_pos, sr_neg, sr_pos, md, row):\n",
    "    \n",
    "    # min row and max row coverage\n",
    "    low_row = sr_neg[0]\n",
    "    high_row = sr_pos[0]\n",
    "    \n",
    "    # confirm our row of interest is within row bounds, if not pass over\n",
    "    if low_row <= row <= high_row:\n",
    "        \n",
    "        # find how far away our row is from the middle\n",
    "        # sc_neg[0] just represents the row for our widest row of coverage\n",
    "        middle_row = sc_neg[0]\n",
    "        low_col = sc_neg[1]\n",
    "        high_col = sc_pos[1]\n",
    "        middle_diff =  middle_row - row\n",
    "        \n",
    "        # middle row of coverage is row of interest, so take full size\n",
    "        if middle_diff == 0:\n",
    "            return [(row, c) for c in range(low_col, high_col + 1)]\n",
    "        \n",
    "        # middle row is above or below row of interest by a certain number of steps\n",
    "        # this means we compress our space by 1 on each side for each step\n",
    "        else:\n",
    "            low_col += abs(middle_diff)\n",
    "            high_col -= abs(middle_diff)\n",
    "            return [(row, c) for c in range(low_col, high_col + 1)]\n",
    "             \n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "\n",
    "def buildSensortDict(data):\n",
    "    \"\"\"Parse input data into a dict for sensor and beacons\"\"\"\n",
    "    sensor_dict = {}\n",
    "    for l in data:\n",
    "\n",
    "        # sensor data\n",
    "        sx = int(l.split('x=')[1].split(',')[0])\n",
    "        sy = int(l.split('y=')[1].split(':')[0])\n",
    "\n",
    "        # beacon data\n",
    "        beacon = l.split('beacon')[1]\n",
    "        bx = int(beacon.split('x=')[1].split(',')[0])\n",
    "        by = int(beacon.split('y=')[1].strip())\n",
    "\n",
    "        # store as row, col\n",
    "        sensor_dict[(sy,sx)] = (by,bx)\n",
    "        \n",
    "    return sensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e81db82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22\n",
      "-2 25\n",
      "finding coverage for ((18, 2), (15, -2))\n",
      "finding coverage for ((16, 9), (16, 10))\n",
      "finding coverage for ((2, 13), (3, 15))\n",
      "finding coverage for ((14, 12), (16, 10))\n",
      "finding coverage for ((20, 10), (16, 10))\n",
      "finding coverage for ((17, 14), (16, 10))\n",
      "finding coverage for ((7, 8), (10, 2))\n",
      "finding coverage for ((0, 2), (10, 2))\n",
      "finding coverage for ((11, 0), (10, 2))\n",
      "finding coverage for ((14, 20), (17, 25))\n",
      "finding coverage for ((20, 17), (22, 21))\n",
      "finding coverage for ((7, 16), (3, 15))\n",
      "finding coverage for ((3, 14), (3, 15))\n",
      "finding coverage for ((1, 20), (3, 15))\n",
      "Solution: 26\n"
     ]
    }
   ],
   "source": [
    "row = 10\n",
    "with open(\"data/day15_sample.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "\n",
    "\n",
    "sensor_dict = buildSensortDict(lines)\n",
    "\n",
    "# calculate boundaries and offset, which is used mainly\n",
    "# for indexing / visualization\n",
    "long_list = []\n",
    "for k,v in sensor_dict.items():\n",
    "    long_list.append(k)\n",
    "    long_list.append(v)\n",
    "long_list = np.asarray(long_list)\n",
    "\n",
    "min_r = np.min(long_list[:,0])\n",
    "max_r = np.max(long_list[:,0])\n",
    "min_c = np.min(long_list[:,1])\n",
    "max_c = np.max(long_list[:,1])\n",
    "\n",
    "print(min_r, max_r)\n",
    "print(min_c, max_c)\n",
    "offset = -1 * min_c\n",
    "\n",
    "# full sample:\n",
    "full_cov = []\n",
    "for k,v in sensor_dict.items():\n",
    "    print(f\"finding coverage for {k,v}\")\n",
    "    md = manhattan_distance(k, v)\n",
    "    a,b,c,d = find_four_points(k, md)\n",
    "    coverage = efficienct_coverage(a,b,c,d, md, row)\n",
    "    full_cov.append(coverage)\n",
    "    \n",
    "final_blocks = flattenArray(full_cov)\n",
    "final_set = {(x[0], x[1]) for x in final_blocks}\n",
    "\n",
    "# remove sensors or blocks\n",
    "# Not done yet -> something is off here. \n",
    "i = 0\n",
    "for fs in final_set:\n",
    "    if fs in sensor_dict.values():\n",
    "        continue\n",
    "    elif fs in sensor_dict.keys():\n",
    "        continue\n",
    "    else:\n",
    "        i += 1\n",
    "        \n",
    "print(f\"Solution: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36812ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-17303 4007257\n",
      "-1085197 4354209\n",
      "finding coverage for ((2163633, 1518415), (1535696, 1111304))\n",
      "finding coverage for ((3598166, 2474609), (4007257, 2691247))\n",
      "finding coverage for ((473371, 426959), (1145419, -529106))\n",
      "finding coverage for ((1984775, 3999598), (2000000, 3975468))\n",
      "finding coverage for ((2951561, 2459256), (2866452, 2132806))\n",
      "finding coverage for ((2862933, 2925882), (3024589, 3325001))\n",
      "finding coverage for ((3882566, 3539174), (3541509, 3132375))\n",
      "finding coverage for ((3798155, 3044887), (3541509, 3132375))\n",
      "finding coverage for ((3506985, 1792818), (2866452, 2132806))\n",
      "finding coverage for ((3304667, 3761945), (3024589, 3325001))\n",
      "finding coverage for ((3823892, 71968), (3401157, -1085197))\n",
      "finding coverage for ((3999748, 2902345), (4007257, 2691247))\n",
      "finding coverage for ((2347435, 2074989), (2866452, 2132806))\n",
      "finding coverage for ((1782338, 1115220), (1535696, 1111304))\n",
      "finding coverage for ((2348958, 369130), (1535696, 1111304))\n",
      "finding coverage for ((1917940, 2525090), (2276026, 2603675))\n",
      "finding coverage for ((3386968, 2861163), (3541509, 3132375))\n",
      "finding coverage for ((2010596, 3995081), (2000000, 3975468))\n",
      "finding coverage for ((534921, 3038274), (-17303, 4354209))\n",
      "finding coverage for ((2868267, 3646366), (3024589, 3325001))\n",
      "finding coverage for ((1653497, 3308360), (2000000, 3975468))\n",
      "finding coverage for ((995783, 1996072), (1535696, 1111304))\n",
      "finding coverage for ((950900, 3852158), (2000000, 3975468))\n",
      "finding coverage for ((2428914, 3061849), (2276026, 2603675))\n",
      "finding coverage for ((3983003, 2788254), (4007257, 2691247))\n",
      "finding coverage for ((1882565, 694411), (1535696, 1111304))\n",
      "finding coverage for ((2551966, 2647250), (2276026, 2603675))\n",
      "finding coverage for ((3166226, 1079431), (2866452, 2132806))\n",
      "finding coverage for ((2196495, 3929172), (2000000, 3975468))\n",
      "finding coverage for ((2487406, 3883296), (2000000, 3975468))\n",
      "finding coverage for ((1529880, 1271911), (1535696, 1111304))\n",
      "Solution: 4861076\n"
     ]
    }
   ],
   "source": [
    "row = 2000000\n",
    "with open(\"data/day15.txt\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "\n",
    "\n",
    "sensor_dict = buildSensortDict(lines)\n",
    "\n",
    "# calculate boundaries and offset, which is used mainly\n",
    "# for indexing / visualization\n",
    "long_list = []\n",
    "for k,v in sensor_dict.items():\n",
    "    long_list.append(k)\n",
    "    long_list.append(v)\n",
    "long_list = np.asarray(long_list)\n",
    "\n",
    "min_r = np.min(long_list[:,0])\n",
    "max_r = np.max(long_list[:,0])\n",
    "min_c = np.min(long_list[:,1])\n",
    "max_c = np.max(long_list[:,1])\n",
    "\n",
    "print(min_r, max_r)\n",
    "print(min_c, max_c)\n",
    "offset = -1 * min_c\n",
    "\n",
    "# full sample:\n",
    "full_cov = []\n",
    "for k,v in sensor_dict.items():\n",
    "    print(f\"finding coverage for {k,v}\")\n",
    "    md = manhattan_distance(k, v)\n",
    "    a,b,c,d = find_four_points(k, md)\n",
    "    coverage = efficienct_coverage(a,b,c,d, md, row)\n",
    "    full_cov.append(coverage)\n",
    "    \n",
    "final_blocks = flattenArray(full_cov)\n",
    "final_set = {(x[0], x[1]) for x in final_blocks}\n",
    "\n",
    "# remove sensors or blocks\n",
    "# Not done yet -> something is off here. \n",
    "i = 0\n",
    "for fs in final_set:\n",
    "    if fs in sensor_dict.values():\n",
    "        continue\n",
    "    elif fs in sensor_dict.keys():\n",
    "        continue\n",
    "    else:\n",
    "        i += 1\n",
    "        \n",
    "print(f\"Solution: {i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
