{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393626d6",
   "metadata": {},
   "source": [
    "### Refactored Original Solution\n",
    "\n",
    "Obviously impossible to iterate through this large of a sequence using lists in Python, numpy also out of question\n",
    "\n",
    "Brief Example of what I Wanted To Do:\n",
    "- Each step keep track of the elements that need to be split in a dictionary: `{'NN': 1, 'NC': 1, 'CB': 1, 'N':1, 'C':1}`\n",
    "    - I keep the start & end as their own single key so that I can just divide every character by 2 at the end. \n",
    "- I then can iterate over the keys & values of my count dictionary:\n",
    "    - Find the insertion \n",
    "    - Take the 0th element of the key and pair with insertion, store off value as count\n",
    "    - Take insertion and pair with 1st element, store off value as count\n",
    "    - Example:\n",
    "        - Assume we are looking at `NN`:\n",
    "        - This will need to generate `NCN`, which can actually be stored as: `NC, CN` since this is what we care about in the next step\n",
    "        - So, our insertion is `C`\n",
    "        - We build one pair of `NC` \n",
    "        - We then build a pair of `CN`\n",
    "        - Notice that C is being handled twice here, this is intentional since each of the `N` elements would be shared by another pair as indicated in the prompt. \n",
    "\n",
    "General Strategy:\n",
    "- Start by building a dictionary of counts that has all pairs to iterate through from initial polymer as well as the first and last elements stored as single keys.\n",
    "    - key: pair of strings (or single string for first & last element)\n",
    "    - value: count (this is why I kept screwing up with actual data, need to not assume a single instance of these keys at the start)\n",
    "- Each step we are going to iterate through the `(key,value)` in the dictionary and:\n",
    "    - Identify the insertion character\n",
    "    - Build out two new pairs -> `(key[0]+insertion)` and `(key[1]+ insertion)`\n",
    "    - store in a new dictionary of counts\n",
    "        - we can assume that the value represents the count for these new pairs since an `insertion`, `key[0]` or `key[1]` will need to exist as many times as the `key` it was generated from. \n",
    "- We then have an updated & expanded dictionary with all proper insertions. We can restart the process on the next step, ensuring we now iterate over the updates. \n",
    "\n",
    "Final Solve:\n",
    "- I intentionally stored the first & last elements of our initial string so that I \"double-count\" every character.\n",
    "    - By double count I mean this: `NNCB` is treated as `N, NN, NC, CB, B`, with each element douibled due to being shared across two pairs. \n",
    "- At the very end I just need to take the last count dictionary (stored with a key being a pair of characters and the value being the count) and count up all the various characters, dividing by 2 due to double-counting\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6487ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def calcCounts(d):\n",
    "    count_dict = defaultdict(lambda: 0)\n",
    "    for k,v in d.items():\n",
    "        if len(k) == 1:\n",
    "            count_dict[k] += (v*0.5)\n",
    "        else:\n",
    "            count_dict[k[0]] += (v*0.5)\n",
    "            count_dict[k[1]] += (v*0.5)\n",
    "            \n",
    "    return count_dict\n",
    "\n",
    "def dataClean(path):\n",
    "    \"\"\"Read in data and output pair insertion dict and initial state string\"\"\"\n",
    "    with open(path) as fh:\n",
    "        data = [line.strip('|\\n') for line in fh.readlines()]\n",
    "\n",
    "    # start by handling initial polymer\n",
    "    poly_temp = data[0]\n",
    "    \n",
    "    pair_insertion = {}\n",
    "\n",
    "    # finish by handling fold details, always starts at 3rd row \n",
    "    for dirs in data[2:]:\n",
    "        r, i = dirs.split(' -> ')\n",
    "        pair_insertion[r] = i\n",
    "    \n",
    "    return poly_temp, pair_insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49db8ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN': 1, 'NC': 1, 'CB': 1, 'N': 1, 'B': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data for test case\n",
    "poly_temp, pair_insertion = dataClean('data/day14_test.txt')\n",
    "\n",
    "# New addition: Generate initiale dict of various counts\n",
    "temp_dict = {}\n",
    "for i in range(len(poly_temp) - 1):\n",
    "    temp_dict[poly_temp[i:i+2]] = 1\n",
    "\n",
    "# Add the ends so i can just divide all values by 1\n",
    "temp_dict[poly_temp[0]] = 1\n",
    "temp_dict[poly_temp[-1]] = 1\n",
    "temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132f298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through 40 (39 more):\n",
    "for _ in range(40):\n",
    "    \n",
    "    # pass over what we just did last step\n",
    "    counter_dict = temp_dict\n",
    "\n",
    "    # definitely need a default dict here for updating keys that didn't exist\n",
    "    temp_dict = defaultdict(lambda: 0)\n",
    "\n",
    "    for k,v in counter_dict.items():\n",
    "\n",
    "        if len(k) == 1:\n",
    "            temp_dict[k] = v\n",
    "            continue\n",
    "\n",
    "        # We can build out the insertion impact to sequence\n",
    "        l = k[0]\n",
    "        i = pair_insertion[k]\n",
    "        r = k[1]\n",
    "\n",
    "        # we build the two new pairs and store off counts from original pair (key)\n",
    "        temp_dict[l+i] += v\n",
    "        temp_dict[i+r] += v\n",
    "\n",
    "# Take final dict & determine various counts\n",
    "temp = calcCounts(temp_dict)\n",
    "assert(temp[max(temp, key = temp.get)] - temp[min(temp, key = temp.get)] == 2188189693529)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac529e91",
   "metadata": {},
   "source": [
    "### Actual 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0c3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "poly_temp, pair_insertion = dataClean('data/day14.txt')\n",
    "\n",
    "# New addition: Generate initiale dict of various counts\n",
    "temp_dict = defaultdict(lambda: 0)\n",
    "\n",
    "for i in range(len(poly_temp) - 1):\n",
    "    temp_dict[poly_temp[i:i+2]] += 1\n",
    "\n",
    "# Add the ends so i can just divide all values by 1\n",
    "temp_dict[poly_temp[0]] = 1\n",
    "temp_dict[poly_temp[-1]] = 1\n",
    "\n",
    "# Start by confirming part 1\n",
    "total_count = defaultdict(lambda: 0)\n",
    "for _ in range(10):\n",
    "    \n",
    "    # pass over what we just did last step\n",
    "    counter_dict = temp_dict\n",
    "\n",
    "    # definitely need a default dict here for updating keys that didn't exist\n",
    "    temp_dict = defaultdict(lambda: 0)\n",
    "\n",
    "    for k,v in counter_dict.items():\n",
    "\n",
    "        if len(k) == 1:\n",
    "            temp_dict[k] = v\n",
    "            continue\n",
    "\n",
    "        # We can build out the insertion impact to sequence\n",
    "        l = k[0]\n",
    "        i = pair_insertion[k]\n",
    "        r = k[1]\n",
    "        \n",
    "        #print(f\"Split {k} into {(l,i)} and {(i,r)}\")\n",
    "\n",
    "        # we build the two new pairs\n",
    "        temp_dict[l+i] += v\n",
    "        temp_dict[i+r] += v\n",
    "\n",
    "    # Take final dict & determine various counts\n",
    "    temp = calcCounts(temp_dict)\n",
    "\n",
    "assert(temp[max(temp, key = temp.get)] - temp[min(temp, key = temp.get)] == 3408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1b3a168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3724343376942.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2\n",
    "poly_temp, pair_insertion = dataClean('data/day14.txt')\n",
    "\n",
    "# New addition: Generate initiale dict of various counts\n",
    "temp_dict = defaultdict(lambda: 0)\n",
    "\n",
    "for i in range(len(poly_temp) - 1):\n",
    "    temp_dict[poly_temp[i:i+2]] += 1\n",
    "\n",
    "# Add the ends so i can just divide all values by 1\n",
    "temp_dict[poly_temp[0]] = 1\n",
    "temp_dict[poly_temp[-1]] = 1\n",
    "\n",
    "# Start by confirming part 1\n",
    "total_count = defaultdict(lambda: 0)\n",
    "for _ in range(40):\n",
    "    \n",
    "    # pass over what we just did last step\n",
    "    counter_dict = temp_dict\n",
    "\n",
    "    # definitely need a default dict here for updating keys that didn't exist\n",
    "    temp_dict = defaultdict(lambda: 0)\n",
    "\n",
    "    for k,v in counter_dict.items():\n",
    "\n",
    "        if len(k) == 1:\n",
    "            temp_dict[k] = v\n",
    "            continue\n",
    "\n",
    "        # We can build out the insertion impact to sequence\n",
    "        l = k[0]\n",
    "        i = pair_insertion[k]\n",
    "        r = k[1]\n",
    "        \n",
    "        #print(f\"Split {k} into {(l,i)} and {(i,r)}\")\n",
    "\n",
    "        # we build the two new pairs\n",
    "        temp_dict[l+i] += v\n",
    "        temp_dict[i+r] += v\n",
    "\n",
    "    # Take final dict & determine various counts\n",
    "    temp = calcCounts(temp_dict)\n",
    "\n",
    "temp[max(temp, key = temp.get)] - temp[min(temp, key = temp.get)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
